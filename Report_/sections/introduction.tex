\section{Introduction}

Blackjack, also known as twenty-one, is the most widely played casino game in the world, largely due to its simple game structure in which a player attempts to get the highest score by drawing cards from a deck. With its long history, various strategies for increasing a players chance of winning, such as card counting, are commonplace. Whilst an optimum strategy for blackjack has been known by statisticians for decades, by drawing on the expected value of future cards \cite{Baldwin01091956}, training an intelligent agent to learn the optimum strategy is an approach not as often taken. Taking this approach (maths is hard for complex systems so just brute force it) by taking a 'tried and tested' approach (find ref and elaborate)

Reinforcement learning is the subfield of machine learning which aims to train an agent in an environment based on a reward, so that an optimum 'policy' can be obtained. 
TALK ABOUT REINFORCEMENT LEARNING PLENTY 
\cite{10.5555/3312046}

note the probabilistic nature of the problem
The probabilistic nature of this topic means that Markov Decision Processes must be involved. 

There are many variations to the game, but for the purposes of this project, the sequence of play was as follows: NOTE ACES RULE

\begin{enumerate}
    \item A card is dealt to the player with value \(C_1\).
    \item For \(n\) iterations, or until a total score of 21 is exceeded, the player can make one of two choices;
    \begin{enumerate} 
        \item Stick, and end the game.
        \item Hit, and receive another card with value \(C_{n+1}\).
    \end{enumerate}
    \item The final score is calculated using
        \begin{equation}
            \text{Score} = 
            \begin{cases}
                (\sum C_n)^2 & \text{if } \sum C_n \le 21\\
                0            & \text{if } \sum C_n >   21\\
            \end{cases}
        \end{equation}
\end{enumerate}

To approach this problem, two situations were considered; infinite, in which the pile of cards being drawn from is infinite, and so, the probability of each card being drawn is equal, and finite, in which the pile of cards being drawn from is finite, meaning unequal probabilities. Doing so allowed for assurance that the agent worked appropriately. 

This paper details the methodology taken for both problem situations, the results of each in context of an optimal result, and a conclusion on the efficacy of this approach.

