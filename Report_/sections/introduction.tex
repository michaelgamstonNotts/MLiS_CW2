\section{Introduction}

Blackjack, also known as twenty-one, is the most widely played casino game in the world, largely due to its simple game structure in which a player attempts to get the highest score by drawing cards from a deck. With its long history, various strategies for increasing a players chance of winning, such as card counting, are commonplace. Whilst an optimum strategy for blackjack has been known by statisticians for decades, by drawing on the expected value of future cards \cite{Baldwin01091956}, training an intelligent agent to learn the optimum strategy is an approach not as often taken. Using intelligent agents like this is known within machine learning communities as 'reinforcement learning'. The advantage of taking a reinforcement learning approach is that it automatically validates theorems. BE MORE PRECISE.  \cite{bidi2023reinforcementlearningcontroltheory}. Reinforcement learning is estimative, so can be used as a premise for basing mathematical models. 

Reinforcement Learning is a subfield of machine learning concerned with teaching an 'agent' to find an optimal set of moves in the context of a wider system. This forms the foundational components; a policy - , a reward signal - defining the agent's goal, an environment - to mimic the behaviour of, and a value function - indicating the long-term desirability of a sequence of states.

 (not Q-learning, that comes in the methodology)
\cite{10.5555/3312046}
The probabilistic nature of this topic means that Markov Decision Processes must be involved. ?

There are many variations to the game, typically involving multiple players and a dealer, but for the purposes of this project the sequence of play was as follows: NOTE ACES RULE

\begin{enumerate}
    \item A card is dealt to the player with value \(C_1\).
    \item For \(n\) iterations, or until a total score of 21 is exceeded, the player can make one of two choices;
    \begin{enumerate} 
        \item Stick, and end the game.
        \item Hit, and receive another card with value \(C_{n+1}\).
    \end{enumerate}
    \item The final score is calculated using
        \begin{equation}
            S = 
            \begin{cases}
                (\sum C_n)^2 & \text{if } \sum C_n \le 21\\
                0            & \text{if } \sum C_n >   21\\
            \end{cases}
        \end{equation}
\end{enumerate}

To approach this problem, two situations were considered; infinite, in which the pile of cards being drawn from is infinite and so, the probability of each card being drawn is equal, and finite, in which the pile of cards being drawn from is finite, meaning unequal probabilities. Doing so allowed for assurance that the agent worked appropriately. 

This paper details the methodology taken for both problem situations, the results of each in context of an optimal result, and a conclusion on the efficacy of this approach.

